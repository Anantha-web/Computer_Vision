{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1\n",
    "\n",
    "youtube-dl -f 'bestvideo[height<=480]+bestaudio/best' https://www.youtube.com/watch?v=bSMxl1V8FSg\n",
    "\n",
    "ffmpeg -i input_video.mp4 -vf fps=30/1 output_frames/frame_%04d.png\n",
    "\n",
    "This command will extract frames from the input video (input_video.mp4) at a rate of 30 frames per second and save them as PNG images in the output_frames directory. Adjust the frame rate according to your preference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Load the pre-trained Viola-Jones Haar cascades face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Function to detect faces in a frame\n",
    "def detect_faces(frame):\n",
    "    # Convert frame to grayscale (required by the detector)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the grayscale image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Load the frames and detect faces in each frame\n",
    "video_capture = cv2.VideoCapture('input_video.mp4')\n",
    "frame_count = 0\n",
    "total_time = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Measure the time taken to process each frame\n",
    "    start_time = time.time()\n",
    "    processed_frame = detect_faces(frame)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate processing time for each frame\n",
    "    frame_processing_time = end_time - start_time\n",
    "    total_time += frame_processing_time\n",
    "    \n",
    "    # Display the processed frame\n",
    "    cv2.imshow('Video', processed_frame)\n",
    "    \n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calculate the average processing time per frame\n",
    "average_time_per_frame = total_time / frame_count\n",
    "print(\"Average processing time per frame:\", average_time_per_frame, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
